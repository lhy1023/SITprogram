{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此份代码用于SIT小组成员调试生成数据集，主要方法已调试好，可方便地在本地运行改进。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入所有需要的模块，如有未安装的库建议pip install\n",
    "# PyAutoGUI是一个纯Python的GUI自动化工具，其目的是可以用程序自动控制鼠标和键盘操作，多平台支持（Windows，OS X，Linux）。\n",
    "#cv2即opencv2，用于实现电脑摄像头的调用等操作\n",
    "#PIL 为Python 常用图像处理模块\n",
    "import pyautogui as pag\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import cv2\n",
    "import urllib3,base64\n",
    "import json\n",
    "from PIL import Image\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 收集脸部照片\n",
    "通过openCV调用摄像头，在按下空格键时保存脸部照片，命名为鼠标所在位置的元组形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25,-0.33\n",
      "0.66,0.29\n",
      "0.13,1.00\n",
      "-0.88,0.49\n",
      "-0.69,-0.20\n",
      "-0.98,-0.77\n",
      "-0.23,-0.75\n",
      "0.22,-1.00\n",
      "0.47,-0.64\n",
      "1.00,-0.81\n"
     ]
    }
   ],
   "source": [
    "#将此处改为初始数据集的保存路径\n",
    "save_path = 'D:/SITdata/'\n",
    "#获取屏幕大小\n",
    "screenWidth,screenHeight = pag.size()\n",
    "#计算获得屏幕原点位置，定为屏幕中心点\n",
    "origin = (screenWidth/2,screenHeight/2)\n",
    "\n",
    "cap=cv2.VideoCapture(0) #调用摄像头，0为电脑自带摄像头，1为外部摄像头\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27: #Esc键退出\n",
    "        break\n",
    "    elif k==32:#空格键保存图片\n",
    "        #获取当前鼠标绝对位置\n",
    "        currMouseX,currMouseY = pag.position() \n",
    "        #将鼠标绝对位置转化为相对于原点的相对坐标，并进行归一化处理\n",
    "        #对归一化处理有疑惑可参考：https://www.jianshu.com/p/95a8f035c86c\n",
    "        curx=(currMouseX-origin[0])/origin[0]\n",
    "        cury=(origin[1]-currMouseY)/origin[1]\n",
    "  \n",
    "        #curx=round(curx,3)\n",
    "        #cury=round(cury,3)\n",
    "        \n",
    "        curxx=format(curx, '.2f')\n",
    "        curyy=format(cury, '.2f')\n",
    "        \n",
    "        currMouse = (curx,cury)\n",
    "\n",
    "        \n",
    "        cv2.imwrite(save_path+curxx+' '+curyy+' .jpg',frame) #修改了一下，方便一些\n",
    "        print(curxx+','+curyy) #方便调试，若成功保存则会立刻在控制台输出\n",
    "    cv2.imshow(\"capture\", frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 裁剪获取眼部图片\n",
    "通过BaiduAI的人脸识别功能获取脸部特征，并根据所需取的脸部特征点，应用Pillow的crop方法进行裁剪，相关参考文档如下：\n",
    "1. BaiduAI 人脸识别技术文档：https://ai.baidu.com/ai-doc/FACE/yk37c1u4t\n",
    "2. Pillow 技术文档：https://pillow.readthedocs.io/en/stable/reference/Image.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaiduAI 发送请求的必备信息，可自行创建应用并修改\n",
    "access_token = '24.49e2a677615b94c0937fea336ea982b6.2592000.1604821923.282335-22192901'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaiduAI 人脸识别方法调用，参数为文件路径，返回BaiduAI平台的反馈\n",
    "def BaiduMethod(filepath):\n",
    "    file = open(filepath,'rb')\n",
    "    img = open(filepath,'rb')\n",
    "    #参数images：图像base64编码 分别base64编码后的2张图片数据，需urlencode，半角逗号分隔，单次请求最大不超过20M\n",
    "    img1 = base64.b64encode(img.read())\n",
    "    request_url = \"https://aip.baidubce.com/rest/2.0/face/v3/detect\"+ \"?access_token=\" + access_token\n",
    "    params = {'image':str(img1,'utf-8'),'image_type':'BASE64','face_field':'landmark'}\n",
    "    headers = {'content-type': 'application/json'}\n",
    "    return requests.post(request_url, data=params, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以单个文件为例，方便数据集收集方法的调试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error_code': 0, 'error_msg': 'SUCCESS', 'log_id': 5505550555059, 'timestamp': 1602249566, 'cached': 0, 'result': {'face_num': 1, 'face_list': [{'face_token': 'f4d87cac35c2065b81ca1a698aa12f06', 'location': {'left': 215.02, 'top': 222.39, 'width': 178, 'height': 181, 'rotation': -5}, 'face_probability': 1, 'angle': {'yaw': 0.9, 'pitch': -3.81, 'roll': -7.67}, 'landmark': [{'x': 268.19, 'y': 247.09}, {'x': 347.1, 'y': 239.04}, {'x': 311.09, 'y': 279.16}, {'x': 315.54, 'y': 332.76}], 'landmark72': [{'x': 220.32, 'y': 273.21}, {'x': 224.77, 'y': 300.48}, {'x': 231.87, 'y': 327.8}, {'x': 242.03, 'y': 354.46}, {'x': 264.13, 'y': 379.26}, {'x': 293.34, 'y': 392.23}, {'x': 321.32, 'y': 393.36}, {'x': 348.67, 'y': 386.47}, {'x': 374.9, 'y': 368.17}, {'x': 392.07, 'y': 340.12}, {'x': 397.1, 'y': 311.8}, {'x': 398.52, 'y': 283.72}, {'x': 397.55, 'y': 256.04}, {'x': 250.74, 'y': 252.88}, {'x': 258.14, 'y': 245.11}, {'x': 267.19, 'y': 242.01}, {'x': 276.3, 'y': 242.88}, {'x': 285.07, 'y': 249.78}, {'x': 277.18, 'y': 252.27}, {'x': 268.11, 'y': 254.23}, {'x': 258.67, 'y': 254.61}, {'x': 268.19, 'y': 247.09}, {'x': 235.89, 'y': 237.02}, {'x': 245.74, 'y': 222.2}, {'x': 260.05, 'y': 217.54}, {'x': 274.4, 'y': 217.47}, {'x': 288.15, 'y': 225.63}, {'x': 274.63, 'y': 226.99}, {'x': 261.01, 'y': 228.14}, {'x': 247.99, 'y': 231.53}, {'x': 331.17, 'y': 245.16}, {'x': 338.47, 'y': 236.65}, {'x': 347.1, 'y': 233.55}, {'x': 356.34, 'y': 234.9}, {'x': 365.16, 'y': 240.88}, {'x': 357.9, 'y': 244.19}, {'x': 348.63, 'y': 245.85}, {'x': 339.5, 'y': 245.74}, {'x': 347.1, 'y': 239.04}, {'x': 324.5, 'y': 222.11}, {'x': 336.1, 'y': 211.16}, {'x': 350.13, 'y': 208.22}, {'x': 364.8, 'y': 209.69}, {'x': 376.87, 'y': 221.87}, {'x': 364.24, 'y': 219.14}, {'x': 351.19, 'y': 218.61}, {'x': 337.96, 'y': 220.49}, {'x': 296.47, 'y': 249.04}, {'x': 294.66, 'y': 263.28}, {'x': 292.88, 'y': 278.33}, {'x': 288.68, 'y': 298.27}, {'x': 300.95, 'y': 294.58}, {'x': 324.3, 'y': 291.96}, {'x': 336.61, 'y': 293.41}, {'x': 328.71, 'y': 274.66}, {'x': 324.23, 'y': 260.39}, {'x': 319.58, 'y': 246.66}, {'x': 311.09, 'y': 279.16}, {'x': 287.13, 'y': 339.08}, {'x': 297.82, 'y': 325.42}, {'x': 314.52, 'y': 321.26}, {'x': 331.47, 'y': 322.11}, {'x': 344.82, 'y': 333.39}, {'x': 331.69, 'y': 339.8}, {'x': 316.72, 'y': 342.71}, {'x': 300.86, 'y': 343.12}, {'x': 300.14, 'y': 332.98}, {'x': 315.18, 'y': 330.23}, {'x': 330.74, 'y': 330.05}, {'x': 329.83, 'y': 331.75}, {'x': 315.52, 'y': 332}, {'x': 301.15, 'y': 334.76}]}]}}\n"
     ]
    }
   ],
   "source": [
    "#此处改为所想读取的单个图片\n",
    "filepath = 'D:/SITdata/(0.13,1.00).jpg'\n",
    "#考虑到百度AI平台的对并发量的限制，此处推荐分开处理，即获取response后不再重复对同一张照片进行处理\n",
    "response = BaiduMethod(filepath)\n",
    "if response:\n",
    "    print (response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 声明\n",
    "图片切割必须解决如下问题：\n",
    "眼部切割所得的图片必须是同样大小的矩形，如何实现？\n",
    "1. 考虑提前定长（如何确保一定包含眼部？不同角度，位置的照片中眼部面积可能不同）\n",
    "2. 根据设备调整模型？\n",
    "\n",
    "暂定解决方案：先完整截取眼部图片，随后进行微调尽量删除无效信息，其次通过resize方法调整图片大小至模型所需输入参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark = response.json()['result']['face_list'][0]['landmark72']\n",
    "img2 = Image.open(filepath)\n",
    "#截取方法待调整\n",
    "box = (landmark[22]['x'],landmark[22]['y'],landmark[22]['x']+150,landmark[22]['y']+50)\n",
    "img3 = img2.crop(box)\n",
    "img3.show() #实时显示切割图片方便微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在调试完眼部图片截取方法后运行该下面模块进行以获取眼部图片数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/SITdata/' #待遍历目录路径\n",
    "save_path = 'D:/SITdata2/'#保存文件目录\n",
    "dirs = os.listdir(path)\n",
    "for file in dirs:\n",
    "    filepath = os.path.join(path,file)\n",
    "    response = BaiduMethod(filepath)\n",
    "    if response and response.json()['error_code']==0:#成功收到且未报错\n",
    "        landmark = response.json()['result']['face_list'][0]['landmark72']\n",
    "        img2 = Image.open(filepath)\n",
    "        #截取方法待调整\n",
    "        box = (landmark[22]['x'],landmark[22]['y'],landmark[22]['x']+150,landmark[22]['y']+50)\n",
    "        img3 = img2.crop(box)\n",
    "        img3.save(save_path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
