{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense, Input\n",
    "'''\n",
    "train_path = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_train_jpg_106/'\n",
    "train_csv = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_train_jpg张皓天改.csv'\n",
    "fea_picture_train_savepath = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_fea_picture_train.npy'\n",
    "xlab_train_savepath = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_xlab_train.npy'\n",
    "ylab_train_savepath = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_ylab_train.npy'\n",
    "\n",
    "test_path = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_test_jpg_18/'\n",
    "test_csv = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_test_jpg张皓天改.csv'\n",
    "fea_picture_test_savepath = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_fea_picture_test.npy'\n",
    "xlab_test_savepath = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_xlab_test.npy'\n",
    "ylab_test_savepath = 'C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_ylab_test.npy'\n",
    "'''\n",
    "train_path = 'MNIST_FC/mnist_image_label/mnist_train_jpg_106/'\n",
    "train_csv = 'MNIST_FC/mnist_image_label/mnist_train_jpg张皓天改.csv'\n",
    "fea_picture_train_savepath = 'MNIST_FC/mnist_image_label/mnist_fea_picture_train.npy'\n",
    "xlab_train_savepath = 'MNIST_FC/mnist_image_label/mnist_xlab_train.npy'\n",
    "ylab_train_savepath = 'MNIST_FC/mnist_image_label/mnist_ylab_train.npy'\n",
    "\n",
    "test_path = 'MNIST_FC/mnist_image_label/mnist_test_jpg_18/'\n",
    "test_csv = 'MNIST_FC/mnist_image_label/mnist_test_jpg张皓天改.csv'\n",
    "fea_picture_test_savepath = 'MNIST_FC/mnist_image_label/mnist_fea_picture_test.npy'\n",
    "xlab_test_savepath = 'MNIST_FC/mnist_image_label/mnist_xlab_test.npy'\n",
    "ylab_test_savepath = 'MNIST_FC/mnist_image_label/mnist_ylab_test.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存放数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateds(path, csv):\n",
    "    f = open(csv, 'r')  # 以只读形式打开csv文件\n",
    "    contents = f.readlines()  # 读取文件中所有行\n",
    "    f.close()  # 关闭csv文件\n",
    "    fea_picture, xlab, ylab = [], [] ,[] # 建立空列表\n",
    "    for content in contents:  # 逐行取出\n",
    "        value = content.split()  # 以空格分开，图片路径为value[0] , 标签x为value[1] ,标签y为value[2]， 存入列表\n",
    "        img1_path = path + value[0] + \" \" + value[1] + \" .jpg\"  # 拼出图片路径和文件名\n",
    "        print(img1_path)\n",
    "        img1 = Image.open(img1_path)  # 读入图片\n",
    "        img1 = np.array(img1.convert('L'))  # 图片变为8位宽灰度值的np.array格式\n",
    "        img1 = img1 / 255.  # 数据归一化 （实现预处理）\n",
    "        fea_picture.append(img1)  # 归一化后的数据，贴到fea_picture\n",
    "        xlab.append(value[0])  # 标签贴到列表x\n",
    "        ylab.append(value[1])  # 标签贴到列表x\n",
    "        print('loading : ' + content)  # 打印状态提示\n",
    "\n",
    "    fea_picture = np.array(fea_picture)  # 变为np.array格式\n",
    "    xlab = np.array(xlab)  # 变为np.array格式\n",
    "    ylab = np.array(ylab)  # 变为np.array格式\n",
    "    xlab = xlab.astype(float)  # 变为浮点型\n",
    "    ylab = ylab.astype(float)  # 变为浮点型\n",
    "    return fea_picture, xlab,ylab  # 返回输入特征fea_picture，返回标签xlab,ylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Generate Datasets-----------------\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.02 0.22 .jpg\n",
      "loading : -0.02 0.22 .jpg,-0.02,0.22\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.04 0.13 .jpg\n",
      "loading : -0.04 0.13 .jpg,-0.04,0.13\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.06 -0.33 .jpg\n",
      "loading : -0.06 -0.33 .jpg,-0.06,-0.33\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.13 -0.20 .jpg\n",
      "loading : -0.13 -0.20 .jpg,-0.13,-0.20\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.16 -0.30 .jpg\n",
      "loading : -0.16 -0.30 .jpg,-0.16,-0.30\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.17 -0.29 .jpg\n",
      "loading : -0.17 -0.29 .jpg,-0.17,-0.29\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.19 0.20 .jpg\n",
      "loading : -0.19 0.20 .jpg,-0.19,0.20\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.21 -0.81 .jpg\n",
      "loading : -0.21 -0.81 .jpg,-0.21,-0.81\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.24 0.14 .jpg\n",
      "loading : -0.24 0.14 .jpg,-0.24,0.14\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.26 -0.76 .jpg\n",
      "loading : -0.26 -0.76 .jpg,-0.26,-0.76\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.26 0.59 .jpg\n",
      "loading : -0.26 0.59 .jpg,-0.26,0.59\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.27 -0.67 .jpg\n",
      "loading : -0.27 -0.67 .jpg,-0.27,-0.67\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.27 -0.71 .jpg\n",
      "loading : -0.27 -0.71 .jpg,-0.27,-0.71\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.28 -0.26 .jpg\n",
      "loading : -0.28 -0.26 .jpg,-0.28,-0.26\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.28 0.50 .jpg\n",
      "loading : -0.28 0.50 .jpg,-0.28,0.50\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.29 0.20 .jpg\n",
      "loading : -0.29 0.20 .jpg,-0.29,0.20\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.31 -0.65 .jpg\n",
      "loading : -0.31 -0.65 .jpg,-0.31,-0.65\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.32 -0.02 .jpg\n",
      "loading : -0.32 -0.02 .jpg,-0.32,-0.02\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.33 0.87 .jpg\n",
      "loading : -0.33 0.87 .jpg,-0.33,0.87\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.37 0.57 .jpg\n",
      "loading : -0.37 0.57 .jpg,-0.37,0.57\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.44 -0.51 .jpg\n",
      "loading : -0.44 -0.51 .jpg,-0.44,-0.51\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.47 -0.04 .jpg\n",
      "loading : -0.47 -0.04 .jpg,-0.47,-0.04\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.49 0.18 .jpg\n",
      "loading : -0.49 0.18 .jpg,-0.49,0.18\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.51 -0.84 .jpg\n",
      "loading : -0.51 -0.84 .jpg,-0.51,-0.84\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.58 -0.00 .jpg\n",
      "loading : -0.58 -0.00 .jpg,-0.58,-0.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.60 1.00 .jpg\n",
      "loading : -0.60 1.00 .jpg,-0.60,1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.64 -0.57 .jpg\n",
      "loading : -0.64 -0.57 .jpg,-0.64,-0.57\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.65 -0.29 .jpg\n",
      "loading : -0.65 -0.29 .jpg,-0.65,-0.29\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.67 0.09 .jpg\n",
      "loading : -0.67 0.09 .jpg,-0.67,0.09\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.69 -0.00 .jpg\n",
      "loading : -0.69 -0.00 .jpg,-0.69,-0.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.69 0.37 .jpg\n",
      "loading : -0.69 0.37 .jpg,-0.69,0.37\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.72 -0.10 .jpg\n",
      "loading : -0.72 -0.10 .jpg,-0.72,-0.10\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.73 -0.32 .jpg\n",
      "loading : -0.73 -0.32 .jpg,-0.73,-0.32\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.75 -0.35 .jpg\n",
      "loading : -0.75 -0.35 .jpg,-0.75,-0.35\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.76 -0.34 .jpg\n",
      "loading : -0.76 -0.34 .jpg,-0.76,-0.34\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.78 -0.62 .jpg\n",
      "loading : -0.78 -0.62 .jpg,-0.78,-0.62\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.81 -0.01 .jpg\n",
      "loading : -0.81 -0.01 .jpg,-0.81,-0.01\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.81 0.52 .jpg\n",
      "loading : -0.81 0.52 .jpg,-0.81,0.52\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.82 -0.32 .jpg\n",
      "loading : -0.82 -0.32 .jpg,-0.82,-0.32\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.85 0.40 .jpg\n",
      "loading : -0.85 0.40 .jpg,-0.85,0.40\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.85 0.72 .jpg\n",
      "loading : -0.85 0.72 .jpg,-0.85,0.72\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.88 0.72 .jpg\n",
      "loading : -0.88 0.72 .jpg,-0.88,0.72\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.92 -0.76 .jpg\n",
      "loading : -0.92 -0.76 .jpg,-0.92,-0.76\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.97 -0.40 .jpg\n",
      "loading : -0.97 -0.40 .jpg,-0.97,-0.40\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-0.99 1.00 .jpg\n",
      "loading : -0.99 1.00 .jpg,-0.99,1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-1.00 -0.19 .jpg\n",
      "loading : -1.00 -0.19 .jpg,-1.00,-0.19\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-1.00 -1.00 .jpg\n",
      "loading : -1.00 -1.00 .jpg,-1.00,-1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-1.00 0.22 .jpg\n",
      "loading : -1.00 0.22 .jpg,-1.00,0.22\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-1.00 0.44 .jpg\n",
      "loading : -1.00 0.44 .jpg,-1.00,0.44\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/-1.00 0.69 .jpg\n",
      "loading : -1.00 0.69 .jpg,-1.00,0.69\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.01 -0.73 .jpg\n",
      "loading : 0.01 -0.73 .jpg,0.01,-0.73\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.03 0.08 .jpg\n",
      "loading : 0.03 0.08 .jpg,0.03,0.08\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.05 0.92 .jpg\n",
      "loading : 0.05 0.92 .jpg,0.05,0.92\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.07 -0.36 .jpg\n",
      "loading : 0.07 -0.36 .jpg,0.07,-0.36\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.13 -0.23 .jpg\n",
      "loading : 0.13 -0.23 .jpg,0.13,-0.23\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.15 -0.39 .jpg\n",
      "loading : 0.15 -0.39 .jpg,0.15,-0.39\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.17 -0.28 .jpg\n",
      "loading : 0.17 -0.28 .jpg,0.17,-0.28\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.19 -0.75 .jpg\n",
      "loading : 0.19 -0.75 .jpg,0.19,-0.75\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.20 -0.25 .jpg\n",
      "loading : 0.20 -0.25 .jpg,0.20,-0.25\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.20 0.90 .jpg\n",
      "loading : 0.20 0.90 .jpg,0.20,0.90\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.23 0.03 .jpg\n",
      "loading : 0.23 0.03 .jpg,0.23,0.03\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.23 0.12 .jpg\n",
      "loading : 0.23 0.12 .jpg,0.23,0.12\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.25 -0.77 .jpg\n",
      "loading : 0.25 -0.77 .jpg,0.25,-0.77\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.26 -0.55 .jpg\n",
      "loading : 0.26 -0.55 .jpg,0.26,-0.55\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.31 0.23 .jpg\n",
      "loading : 0.31 0.23 .jpg,0.31,0.23\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.31 0.94 .jpg\n",
      "loading : 0.31 0.94 .jpg,0.31,0.94\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.32 -0.33 .jpg\n",
      "loading : 0.32 -0.33 .jpg,0.32,-0.33\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.33 -0.38 .jpg\n",
      "loading : 0.33 -0.38 .jpg,0.33,-0.38\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.33 -0.69 .jpg\n",
      "loading : 0.33 -0.69 .jpg,0.33,-0.69\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.35 -0.66 .jpg\n",
      "loading : 0.35 -0.66 .jpg,0.35,-0.66\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.36 0.65 .jpg\n",
      "loading : 0.36 0.65 .jpg,0.36,0.65\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.40 -0.13 .jpg\n",
      "loading : 0.40 -0.13 .jpg,0.40,-0.13\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.43 0.05 .jpg\n",
      "loading : 0.43 0.05 .jpg,0.43,0.05\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.44 0.36 .jpg\n",
      "loading : 0.44 0.36 .jpg,0.44,0.36\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.45 -0.79 .jpg\n",
      "loading : 0.45 -0.79 .jpg,0.45,-0.79\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.46 0.18 .jpg\n",
      "loading : 0.46 0.18 .jpg,0.46,0.18\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.47 0.27 .jpg\n",
      "loading : 0.47 0.27 .jpg,0.47,0.27\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.47 0.36 .jpg\n",
      "loading : 0.47 0.36 .jpg,0.47,0.36\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.49 0.16 .jpg\n",
      "loading : 0.49 0.16 .jpg,0.49,0.16\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.50 -0.11 .jpg\n",
      "loading : 0.50 -0.11 .jpg,0.50,-0.11\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.50 -0.40 .jpg\n",
      "loading : 0.50 -0.40 .jpg,0.50,-0.40\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.52 -0.04 .jpg\n",
      "loading : 0.52 -0.04 .jpg,0.52,-0.04\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.55 -0.30 .jpg\n",
      "loading : 0.55 -0.30 .jpg,0.55,-0.30\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.55 -0.38 .jpg\n",
      "loading : 0.55 -0.38 .jpg,0.55,-0.38\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.57 0.26 .jpg\n",
      "loading : 0.57 0.26 .jpg,0.57,0.26\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.58 0.27 .jpg\n",
      "loading : 0.58 0.27 .jpg,0.58,0.27\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.60 -0.19 .jpg\n",
      "loading : 0.60 -0.19 .jpg,0.60,-0.19\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.65 0.39 .jpg\n",
      "loading : 0.65 0.39 .jpg,0.65,0.39\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.65 0.56 .jpg\n",
      "loading : 0.65 0.56 .jpg,0.65,0.56\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.66 -0.75 .jpg\n",
      "loading : 0.66 -0.75 .jpg,0.66,-0.75\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.67 -0.02 .jpg\n",
      "loading : 0.67 -0.02 .jpg,0.67,-0.02\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.67 1.00 .jpg\n",
      "loading : 0.67 1.00 .jpg,0.67,1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.70 -0.55 .jpg\n",
      "loading : 0.70 -0.55 .jpg,0.70,-0.55\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.78 -0.02 .jpg\n",
      "loading : 0.78 -0.02 .jpg,0.78,-0.02\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.80 0.47 .jpg\n",
      "loading : 0.80 0.47 .jpg,0.80,0.47\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.81 -0.20 .jpg\n",
      "loading : 0.81 -0.20 .jpg,0.81,-0.20\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.83 -0.42 .jpg\n",
      "loading : 0.83 -0.42 .jpg,0.83,-0.42\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.83 -0.54 .jpg\n",
      "loading : 0.83 -0.54 .jpg,0.83,-0.54\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.86 -0.01 .jpg\n",
      "loading : 0.86 -0.01 .jpg,0.86,-0.01\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.87 -0.85 .jpg\n",
      "loading : 0.87 -0.85 .jpg,0.87,-0.85\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.89 -0.20 .jpg\n",
      "loading : 0.89 -0.20 .jpg,0.89,-0.20\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.90 -0.38 .jpg\n",
      "loading : 0.90 -0.38 .jpg,0.90,-0.38\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.91 0.64 .jpg\n",
      "loading : 0.91 0.64 .jpg,0.91,0.64\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/1.00 -1.00 .jpg\n",
      "loading : 1.00 -1.00 .jpg,1.00,-1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/1.00 0.06 .jpg\n",
      "loading : 1.00 0.06 .jpg,1.00,0.06\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_train_jpg_106/1.00 0.15 .jpg\n",
      "loading : 1.00 0.15 .jpg,1.00,0.15\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-0.05 -0.81 .jpg\n",
      "loading : -0.05 -0.81 .jpg,-0.05,-0.81\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-0.18 0.15 .jpg\n",
      "loading : -0.18 0.15 .jpg,-0.18,0.15\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-0.80 0.63 .jpg\n",
      "loading : -0.80 0.63 .jpg,-0.80,0.63\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-0.82 -0.61 .jpg\n",
      "loading : -0.82 -0.61 .jpg,-0.82,-0.61\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-0.85 -0.68 .jpg\n",
      "loading : -0.85 -0.68 .jpg,-0.85,-0.68\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-0.94 -0.22 .jpg\n",
      "loading : -0.94 -0.22 .jpg,-0.94,-0.22\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-1.00 -0.03 .jpg\n",
      "loading : -1.00 -0.03 .jpg,-1.00,-0.03\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-1.00 -1.00 .jpg\n",
      "loading : -1.00 -1.00 .jpg,-1.00,-1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/-1.00 1.00 .jpg\n",
      "loading : -1.00 1.00 .jpg,-1.00,1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/0.13 -0.29 .jpg\n",
      "loading : 0.13 -0.29 .jpg,0.13,-0.29\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/0.27 0.77 .jpg\n",
      "loading : 0.27 0.77 .jpg,0.27,0.77\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/0.37 -0.77 .jpg\n",
      "loading : 0.37 -0.77 .jpg,0.37,-0.77\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/0.53 0.44 .jpg\n",
      "loading : 0.53 0.44 .jpg,0.53,0.44\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/0.56 -0.38 .jpg\n",
      "loading : 0.56 -0.38 .jpg,0.56,-0.38\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/0.64 0.38 .jpg\n",
      "loading : 0.64 0.38 .jpg,0.64,0.38\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/0.67 -0.25 .jpg\n",
      "loading : 0.67 -0.25 .jpg,0.67,-0.25\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/1.00 -1.00 .jpg\n",
      "loading : 1.00 -1.00 .jpg,1.00,-1.00\n",
      "\n",
      "MNIST_FC/mnist_image_label/mnist_test_jpg_18/1.00 1.00 .jpg\n",
      "loading : 1.00 1.00 .jpg,1.00,1.00\n",
      "\n",
      "-------------Save Datasets-----------------\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(fea_picture_train_savepath) and os.path.exists(xlab_train_savepath) and os.path.exists(\n",
    "        ylab_train_savepath) and os.path.exists(fea_picture_test_savepath) and os.path.exists(xlab_test_savepath) and os.path.exists(\n",
    "        ylab_test_savepath):\n",
    "    print('-------------Load Datasets-----------------')\n",
    "    fea_picture_train_save = np.load(fea_picture_train_savepath)\n",
    "    xlab_train = np.load(xlab_train_savepath)\n",
    "    ylab_train = np.load(ylab_train_savepath)\n",
    "    fea_picture_test_save = np.load(fea_picture_test_savepath)\n",
    "    xlab_test = np.load(xlab_test_savepath)\n",
    "    ylab_test = np.load(ylab_test_savepath)\n",
    "    fea_picture_train = np.reshape(fea_picture_train_save, (len(fea_picture_train_save), 50, 150))\n",
    "    fea_picture_test = np.reshape(fea_picture_test_save, (len(fea_picture_test_save), 50, 150))\n",
    "else:\n",
    "    print('-------------Generate Datasets-----------------')\n",
    "    fea_picture_train, xlab_train, ylab_train = generateds(train_path, train_csv)\n",
    "    fea_picture_test, xlab_test, ylab_test = generateds(test_path, test_csv)\n",
    "\n",
    "    print('-------------Save Datasets-----------------')\n",
    "    \n",
    "    fea_picture_train_save = np.reshape(fea_picture_train, (len(fea_picture_train), -1))\n",
    "    fea_picture_test_save = np.reshape(fea_picture_test, (len(fea_picture_test), -1))\n",
    "    np.save(fea_picture_train_savepath, fea_picture_train_save)\n",
    "    np.save(xlab_train_savepath, xlab_train)\n",
    "    np.save(ylab_train_savepath, ylab_train)\n",
    "    np.save(fea_picture_test_savepath, fea_picture_test_save)\n",
    "    np.save(xlab_test_savepath, xlab_test)\n",
    "    np.save(ylab_test_savepath, ylab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_picture_train = fea_picture_train.reshape(fea_picture_train.shape[0], 50, 150, 1)\n",
    "fea_picture_test = fea_picture_test.reshape(fea_picture_test.shape[0], 50, 150, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fea_picture_train.shape:\n",
      " (106, 50, 150, 1)\n",
      "xlab_train.shape:\n",
      " (106,)\n",
      "ylab_train.shape:\n",
      " (106,)\n",
      "fea_picture_test.shape:\n",
      " (18, 50, 150, 1)\n",
      "xlab_test.shape:\n",
      " (18,)\n",
      "ylab_test.shape:\n",
      " (18,)\n"
     ]
    }
   ],
   "source": [
    "# 打印出整个训练集输入特征的形状\n",
    "print(\"fea_picture_train.shape:\\n\", fea_picture_train.shape)\n",
    "# 打印出整个训练集标签的形状\n",
    "print(\"xlab_train.shape:\\n\", xlab_train.shape)\n",
    "print(\"ylab_train.shape:\\n\", ylab_train.shape)\n",
    "# 打印出整个测试集输入特征的形状\n",
    "print(\"fea_picture_test.shape:\\n\", fea_picture_test.shape)\n",
    "# 打印出整个测试集标签的形状\n",
    "print(\"xlab_test.shape:\\n\", xlab_test.shape)\n",
    "print(\"ylab_test.shape:\\n\", ylab_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = tf.keras.models.Sequential([\\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 150, 1), padding='same'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    #     tf.keras.layers.BatchNormalization(),\\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Flatten(),\\n    tf.keras.layers.Dense(1024, activation='relu'),\\n    tf.keras.layers.Dense(1024,activation = 'relu'),\\n    tf.keras.layers.Dense(512,activation = 'relu'),\\n    tf.keras.layers.Dropout(0.25),\\n    tf.keras.layers.Dense(1024, activation='linear')\\n\\n])\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型x坐标\n",
    "model1_in = Input(shape=(50, 150, 1))\n",
    "model1_out = Conv2D(32, (3, 3), activation='relu', input_shape=(50, 150, 1), padding='same')(model1_in)\n",
    "model1_out = MaxPool2D(2, 2)(model1_out)\n",
    "model1_out = Conv2D(32, (3, 3), activation='relu', padding='same')(model1_out)\n",
    "model1_out = MaxPool2D(2, 2)(model1_out)\n",
    "model1_out = Conv2D(64, (3, 3), activation='relu', padding='same')(model1_out)\n",
    "model1_out = MaxPool2D(2, 2)(model1_out)\n",
    "model1_out = Conv2D(64, (3, 3), activation='relu', padding='same')(model1_out)\n",
    "model1_out = MaxPool2D(2, 2)(model1_out)\n",
    "model1_out = Flatten()(model1_out)\n",
    "model1_out = Dense(1024, activation='relu')(model1_out)\n",
    "model1_out = Dense(1024, activation='relu')(model1_out)\n",
    "model1_out = Dense(512,activation = 'relu')(model1_out)\n",
    "model1_out = Dropout(0.25)(model1_out)\n",
    "model1_out = Dense(1024, activation='linear')(model1_out)\n",
    "\n",
    "'''model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50, 150, 1), padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    #     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(1024,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(512,activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(1024, activation='linear')\n",
    "\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型y坐标\n",
    "model2_in = Input(shape=(50, 150, 1))\n",
    "model2_out = Conv2D(32, (3, 3), activation='relu', input_shape=(50, 150, 1), padding='same')(model2_in)\n",
    "model2_out = MaxPool2D(2, 2)(model2_out)\n",
    "model2_out = Conv2D(32, (3, 3), activation='relu', padding='same')(model2_out)\n",
    "model2_out = MaxPool2D(2, 2)(model2_out)\n",
    "model2_out = Conv2D(64, (3, 3), activation='relu', padding='same')(model2_out)\n",
    "model2_out = MaxPool2D(2, 2)(model2_out)\n",
    "model2_out = Conv2D(64, (3, 3), activation='relu', padding='same')(model2_out)\n",
    "model2_out = MaxPool2D(2, 2)(model2_out)\n",
    "model2_out = Flatten()(model2_out)\n",
    "model2_out = Dense(1024, activation='relu')(model2_out)\n",
    "model2_out = Dense(1024, activation='relu')(model2_out)\n",
    "model2_out = Dense(512,activation = 'relu')(model2_out)\n",
    "model2_out = Dropout(0.25)(model2_out)\n",
    "model2_out = Dense(1024, activation='linear')(model2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拼接\n",
    "\n",
    "merged_model = Model(inputs=[model1_in, model2_in], outputs=[model1_out,model2_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model.compile(optimizer='adam',\\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\\n              metrics=['sparse_categorical_accuracy'])\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自己定义损失函数，方式参照https://blog.csdn.net/Kyf_Coffee/article/details/53914778\n",
    "#用均方误差做损失函数\n",
    "merged_model.compile(loss='mse',\n",
    "              optimizer='adam')#http://www.voidcn.com/article/p-wwcfusbv-buo.html分类指标才需要metrics\n",
    "'''model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 断点续训\n",
    "checkpoint_save_path = \".ipynb_checkpoints/back_up.ckpt\"\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    merged_model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4/4 [==============================] - 4s 886ms/step - loss: 0.1298 - dense_33_loss: 0.0259 - dense_37_loss: 0.1039 - val_loss: 0.2176 - val_dense_33_loss: 0.0810 - val_dense_37_loss: 0.1367\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.0975 - dense_33_loss: 0.0165 - dense_37_loss: 0.0810 - val_loss: 0.2391 - val_dense_33_loss: 0.0900 - val_dense_37_loss: 0.1491\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1006 - dense_33_loss: 0.0168 - dense_37_loss: 0.0838 - val_loss: 0.1928 - val_dense_33_loss: 0.0765 - val_dense_37_loss: 0.1163\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0680 - dense_33_loss: 0.0127 - dense_37_loss: 0.0553 - val_loss: 0.1748 - val_dense_33_loss: 0.0765 - val_dense_37_loss: 0.0982\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0822 - dense_33_loss: 0.0158 - dense_37_loss: 0.0663 - val_loss: 0.1861 - val_dense_33_loss: 0.0671 - val_dense_37_loss: 0.1191\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 4s 991ms/step - loss: 0.0663 - dense_33_loss: 0.0149 - dense_37_loss: 0.0514 - val_loss: 0.1156 - val_dense_33_loss: 0.0422 - val_dense_37_loss: 0.0735\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0460 - dense_33_loss: 0.0121 - dense_37_loss: 0.0339 - val_loss: 0.0975 - val_dense_33_loss: 0.0512 - val_dense_37_loss: 0.0463\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0398 - dense_33_loss: 0.0087 - dense_37_loss: 0.0311 - val_loss: 0.1044 - val_dense_33_loss: 0.0449 - val_dense_37_loss: 0.0595\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 0.0398 - dense_33_loss: 0.0089 - dense_37_loss: 0.0309 - val_loss: 0.0956 - val_dense_33_loss: 0.0558 - val_dense_37_loss: 0.0398\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0324 - dense_33_loss: 0.0102 - dense_37_loss: 0.0223 - val_loss: 0.0751 - val_dense_33_loss: 0.0411 - val_dense_37_loss: 0.0340\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0300 - dense_33_loss: 0.0091 - dense_37_loss: 0.0209 - val_loss: 0.0853 - val_dense_33_loss: 0.0505 - val_dense_37_loss: 0.0348\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0267 - dense_33_loss: 0.0089 - dense_37_loss: 0.0178 - val_loss: 0.0804 - val_dense_33_loss: 0.0514 - val_dense_37_loss: 0.0290\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.0268 - dense_33_loss: 0.0082 - dense_37_loss: 0.0187 - val_loss: 0.0849 - val_dense_33_loss: 0.0523 - val_dense_37_loss: 0.0326\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.0255 - dense_33_loss: 0.0074 - dense_37_loss: 0.0181 - val_loss: 0.1191 - val_dense_33_loss: 0.0515 - val_dense_37_loss: 0.0675\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0368 - dense_33_loss: 0.0073 - dense_37_loss: 0.0295 - val_loss: 0.0820 - val_dense_33_loss: 0.0430 - val_dense_37_loss: 0.0391\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.0253 - dense_33_loss: 0.0065 - dense_37_loss: 0.0188 - val_loss: 0.0943 - val_dense_33_loss: 0.0563 - val_dense_37_loss: 0.0380\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.0252 - dense_33_loss: 0.0079 - dense_37_loss: 0.0173 - val_loss: 0.0785 - val_dense_33_loss: 0.0410 - val_dense_37_loss: 0.0374\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.0225 - dense_33_loss: 0.0073 - dense_37_loss: 0.0152 - val_loss: 0.0756 - val_dense_33_loss: 0.0465 - val_dense_37_loss: 0.0291\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 2s 563ms/step - loss: 0.0242 - dense_33_loss: 0.0074 - dense_37_loss: 0.0168 - val_loss: 0.0795 - val_dense_33_loss: 0.0494 - val_dense_37_loss: 0.0300\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.0212 - dense_33_loss: 0.0086 - dense_37_loss: 0.0126 - val_loss: 0.0770 - val_dense_33_loss: 0.0423 - val_dense_37_loss: 0.0347\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.0181 - dense_33_loss: 0.0063 - dense_37_loss: 0.0119 - val_loss: 0.0832 - val_dense_33_loss: 0.0564 - val_dense_37_loss: 0.0268\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 4s 969ms/step - loss: 0.0154 - dense_33_loss: 0.0070 - dense_37_loss: 0.0085 - val_loss: 0.0638 - val_dense_33_loss: 0.0402 - val_dense_37_loss: 0.0236\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0162 - dense_33_loss: 0.0062 - dense_37_loss: 0.0100 - val_loss: 0.0908 - val_dense_33_loss: 0.0614 - val_dense_37_loss: 0.0294\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0162 - dense_33_loss: 0.0069 - dense_37_loss: 0.0094 - val_loss: 0.0679 - val_dense_33_loss: 0.0377 - val_dense_37_loss: 0.0301\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0188 - dense_33_loss: 0.0076 - dense_37_loss: 0.0112 - val_loss: 0.0936 - val_dense_33_loss: 0.0468 - val_dense_37_loss: 0.0468\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0233 - dense_33_loss: 0.0073 - dense_37_loss: 0.0160 - val_loss: 0.0647 - val_dense_33_loss: 0.0371 - val_dense_37_loss: 0.0276\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0226 - dense_33_loss: 0.0066 - dense_37_loss: 0.0160 - val_loss: 0.0864 - val_dense_33_loss: 0.0530 - val_dense_37_loss: 0.0334\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0220 - dense_33_loss: 0.0062 - dense_37_loss: 0.0158 - val_loss: 0.0889 - val_dense_33_loss: 0.0493 - val_dense_37_loss: 0.0396\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0232 - dense_33_loss: 0.0060 - dense_37_loss: 0.0173 - val_loss: 0.0790 - val_dense_33_loss: 0.0359 - val_dense_37_loss: 0.0430\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0179 - dense_33_loss: 0.0057 - dense_37_loss: 0.0122 - val_loss: 0.0676 - val_dense_33_loss: 0.0422 - val_dense_37_loss: 0.0255\n"
     ]
    }
   ],
   "source": [
    "#训练模型，如果修改模型记得把断点续寻前面存储的模型删除掉\n",
    "history = merged_model.fit([fea_picture_train , fea_picture_train], [xlab_train , ylab_train], batch_size=32, epochs=30, validation_data=([fea_picture_test , fea_picture_test], [xlab_test , ylab_test]), validation_freq=1,\n",
    "                   callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 50, 150, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 50, 150, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 50, 150, 32)  320         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 50, 150, 32)  320         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling2D) (None, 25, 75, 32)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling2D) (None, 25, 75, 32)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 25, 75, 32)   9248        max_pooling2d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 25, 75, 32)   9248        max_pooling2d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling2D) (None, 12, 37, 32)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling2D) (None, 12, 37, 32)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 37, 64)   18496       max_pooling2d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 37, 64)   18496       max_pooling2d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling2D) (None, 6, 18, 64)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D) (None, 6, 18, 64)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 6, 18, 64)    36928       max_pooling2d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 18, 64)    36928       max_pooling2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling2D) (None, 3, 9, 64)     0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 3, 9, 64)     0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 1728)         0           max_pooling2d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1728)         0           max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1024)         1770496     flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 1024)         1770496     flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1024)         1049600     dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 1024)         1049600     dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 512)          524800      dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 512)          524800      dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512)          0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1024)         525312      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 1024)         525312      dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,870,400\n",
      "Trainable params: 7,870,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merged_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示训练集和验证集的loss曲线\n",
    "#只要两条曲线都在下降就正常\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "'''plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()'''\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input the number of test pictures:1\n",
      "the path of test picture:C:/Users/Lenovo/Desktop/模型/class4存在bug/MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.32 -0.33 .jpg\n",
      "[array([[-0.00424427, -0.00646496, -0.00935732, ..., -0.02068723,\n",
      "        -0.01257947, -0.00510578]], dtype=float32), array([[-0.17271563, -0.16742751, -0.16130981, ..., -0.15773861,\n",
      "        -0.17038997, -0.16640323]], dtype=float32)]\n",
      "\n",
      "\n",
      "0.013677726 -0.14941151\n"
     ]
    }
   ],
   "source": [
    "preNum = int(input(\"input the number of test pictures:\"))\n",
    "#测试用：1  MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.01 -0.73 .jpg\n",
    "           #MNIST_FC/mnist_image_label/mnist_train_jpg_106/0.32 -0.33 .jpg\n",
    "for i in range(preNum):\n",
    "    image_path = input(\"the path of test picture:\")\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((50, 150), Image.ANTIALIAS)\n",
    "    img_arr = np.array(img.convert('L'))\n",
    "   \n",
    "    '''for i in range(150):\n",
    "        for j in range(50):\n",
    "            if img_arr[i][j] < 200:\n",
    "                img_arr[i][j] = 255\n",
    "            else:\n",
    "                img_arr[i][j] = 0'''\n",
    "\n",
    "    img_arr = img_arr / 255.0\n",
    "\n",
    "    x_predict = img_arr[tf.newaxis, ..., tf.newaxis]\n",
    "    result = merged_model.predict([x_predict , x_predict ])\n",
    "    print(result)\n",
    "    predx = np.max(result[0])\n",
    "    predy = np.max(result[1])\n",
    "\n",
    "    print('\\n')\n",
    "    tf.print(predx , predy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
