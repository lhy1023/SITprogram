{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简介\n",
    "本版本更新于2021/2/13，相关参数说明如下：\n",
    "* 人脸关键点识别方法：Baidu AI-人脸识别(待改进)\n",
    "* 目标数据集格式：\n",
    " 1. 特征：**整张面部图片** 标签：鼠标坐标（相对位置+归一化）\n",
    " 2. 特征：左右脸宽度之比 & 鼻尖-眼部上侧高度差值 标签：鼠标坐标\n",
    "* Python环境： python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入所有需要的模块，如有未安装的库建议pip install\n",
    "# PyAutoGUI是一个纯Python的GUI自动化工具，其目的是可以用程序自动控制鼠标和键盘操作，多平台支持（Windows，OS X，Linux）。\n",
    "#cv2即opencv2，用于实现电脑摄像头的调用等操作\n",
    "#PIL 为Python 常用图像处理模块\n",
    "import pyautogui as pag\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import cv2\n",
    "import urllib3,base64\n",
    "import json\n",
    "from PIL import Image\n",
    "from urllib.parse import urlencode\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  一、收集并保存摄像头照片\n",
    "通过openCV调用摄像头，在按下空格键时保存照片，命名为鼠标所在位置的元组形式。\n",
    "\n",
    "运行此单元格后将弹出名为Capture的摄像头视频页面，敲击空格即可保存图片，通过ESC键终止运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14066666666666666, 0.414)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6d072e563908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#调用摄像头，0为电脑自带摄像头，1为外部摄像头\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#Esc键退出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#将此处改为初始数据集的保存路径\n",
    "save_path = 'D:/UserData/Documents/Jupyter/EyeTrack/DataSet/'\n",
    "#获取屏幕大小\n",
    "screenWidth,screenHeight = pag.size()\n",
    "#计算获得屏幕原点位置，定为屏幕中心点\n",
    "origin = (screenWidth/2,screenHeight/2)\n",
    "\n",
    "cap=cv2.VideoCapture(0) #调用摄像头，0为电脑自带摄像头，1为外部摄像头\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27: #Esc键退出\n",
    "        break\n",
    "    elif k==32:#空格键保存图片\n",
    "        #获取当前鼠标绝对位置\n",
    "        currMouseX,currMouseY = pag.position() \n",
    "        #将鼠标绝对位置转化为相对于原点的相对坐标，并进行归一化处理\n",
    "        #对归一化处理有疑惑可参考：https://www.jianshu.com/p/95a8f035c86c\n",
    "        currMouse = ((currMouseX-origin[0])/origin[0],(origin[1]-currMouseY)/origin[1])\n",
    "        \n",
    "        cv2.imwrite(save_path+str(currMouse)+'.jpg',frame)\n",
    "        print(currMouse) #方便调试，若成功保存则会立刻在控制台输出\n",
    "    cv2.imshow(\"capture\", frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、调用人脸识别API获取关键点信息\n",
    "调用百度AI-人脸识别以照片进行处理，并找出照片中的脸部关键点信息，以方便对图片信息进行下一步的处理。\n",
    "\n",
    "BaiduAI 相关技术文档：https://ai.baidu.com/ai-doc/FACE/yk37c1u4t\n",
    "\n",
    "注：此方法仅支持2QPS的查询率（即每秒2次的查询率），如需实际应用或用于实时演示则需更改此部分的代码或购买更大的处理能力。也可通过申请多个百度账号，建立账号池以增大qps。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.2eb0dab646cd08942950a16d59db84d4.2592000.1615815823.282335-22192901\n"
     ]
    }
   ],
   "source": [
    "# 首先通过百度AI提供的方法获取申请服务时的ID参数access_token，此参数至少一个月需更新一次，此处提供的为我的access_token\n",
    "import requests \n",
    "\n",
    "# client_id 为官网获取的AK， client_secret 为官网获取的SK\n",
    "host = 'https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id=QGsRMBXewEr9zcmapc3HeIVC&client_secret=PloEXIBs9Sf30tYVVtOppftGGgnqTwNh'\n",
    "access_token = 'wait_to_get'\n",
    "response = requests.get(host)\n",
    "if response:\n",
    "    access_token = response.json()['access_token']\n",
    "    print(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaiduAI 人脸识别方法调用，参数为文件路径，返回BaiduAI平台的反馈\n",
    "def BaiduMethod(filepath):\n",
    "    file = open(filepath,'rb')\n",
    "    img = open(filepath,'rb')\n",
    "    #参数images：图像base64编码 分别base64编码后的2张图片数据，需urlencode，半角逗号分隔，单次请求最大不超过20M\n",
    "    img1 = base64.b64encode(img.read())\n",
    "    request_url = \"https://aip.baidubce.com/rest/2.0/face/v3/detect\"+ \"?access_token=\" + access_token\n",
    "    params = {'image':str(img1,'utf-8'),'image_type':'BASE64','face_field':'landmark'}\n",
    "    headers = {'content-type': 'application/json'}\n",
    "    return requests.post(request_url, data=params, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error_code': 0, 'error_msg': 'SUCCESS', 'log_id': 7925354510199, 'timestamp': 1613221527, 'cached': 0, 'result': {'face_num': 1, 'face_list': [{'face_token': '7ceb0c9266de70bdb7e56d4f20f9f650', 'location': {'left': 277.74, 'top': 66.96, 'width': 197, 'height': 209, 'rotation': 2}, 'face_probability': 1, 'angle': {'yaw': -3.76, 'pitch': -6.47, 'roll': -0.05}, 'landmark': [{'x': 332.14, 'y': 109.03}, {'x': 426.11, 'y': 113.61}, {'x': 381.88, 'y': 149.83}, {'x': 376.32, 'y': 211.38}], 'landmark72': [{'x': 273.85, 'y': 137.52}, {'x': 275, 'y': 168.56}, {'x': 278.64, 'y': 199.33}, {'x': 286.85, 'y': 230}, {'x': 309.34, 'y': 259.37}, {'x': 340.03, 'y': 276.43}, {'x': 371.56, 'y': 281.08}, {'x': 401.48, 'y': 277.06}, {'x': 431.51, 'y': 260.88}, {'x': 452.94, 'y': 233.46}, {'x': 462.94, 'y': 204.26}, {'x': 468.68, 'y': 174.71}, {'x': 471.56, 'y': 145.52}, {'x': 310.94, 'y': 113.34}, {'x': 321.13, 'y': 105.67}, {'x': 332.19, 'y': 103.28}, {'x': 342.57, 'y': 105.49}, {'x': 352.52, 'y': 113.46}, {'x': 342.49, 'y': 115.23}, {'x': 331.84, 'y': 116.43}, {'x': 320.73, 'y': 115.74}, {'x': 332.14, 'y': 109.03}, {'x': 297.21, 'y': 92.47}, {'x': 310.58, 'y': 74.54}, {'x': 329.28, 'y': 69.21}, {'x': 347.54, 'y': 70.74}, {'x': 363.04, 'y': 83.08}, {'x': 346.25, 'y': 83.12}, {'x': 329.3, 'y': 82.66}, {'x': 312.7, 'y': 85.71}, {'x': 407.06, 'y': 116.27}, {'x': 417.82, 'y': 108.73}, {'x': 428.64, 'y': 107.65}, {'x': 438.63, 'y': 111.23}, {'x': 447.31, 'y': 120.02}, {'x': 437.97, 'y': 121.55}, {'x': 427.46, 'y': 120.98}, {'x': 416.99, 'y': 118.89}, {'x': 426.11, 'y': 113.61}, {'x': 402.22, 'y': 85.72}, {'x': 417.89, 'y': 74.82}, {'x': 435.23, 'y': 75.05}, {'x': 451.98, 'y': 82.11}, {'x': 461.97, 'y': 100.45}, {'x': 448.93, 'y': 92.72}, {'x': 434.26, 'y': 88.24}, {'x': 418.06, 'y': 87.05}, {'x': 366.65, 'y': 113.54}, {'x': 362.14, 'y': 129.55}, {'x': 357.61, 'y': 145.81}, {'x': 348.89, 'y': 167.75}, {'x': 365.33, 'y': 165.82}, {'x': 394.12, 'y': 166.96}, {'x': 407.75, 'y': 169.75}, {'x': 401.45, 'y': 147.08}, {'x': 398, 'y': 130.8}, {'x': 394.35, 'y': 114.74}, {'x': 381.88, 'y': 149.83}, {'x': 336.27, 'y': 212.25}, {'x': 355.71, 'y': 200.78}, {'x': 378.21, 'y': 199.16}, {'x': 398.68, 'y': 202.58}, {'x': 413.75, 'y': 215.58}, {'x': 395.73, 'y': 221.72}, {'x': 375.85, 'y': 222.49}, {'x': 355, 'y': 220.06}, {'x': 356.52, 'y': 209.83}, {'x': 377.23, 'y': 209.7}, {'x': 396.57, 'y': 211.41}, {'x': 395.33, 'y': 212.4}, {'x': 376.62, 'y': 210.57}, {'x': 356.98, 'y': 210.7}]}]}}\n"
     ]
    }
   ],
   "source": [
    "#此处改为所想读取的单个图片\n",
    "filepath = 'D:/UserData/Documents/Jupyter/EyeTrack/DataSet/(-0.5206666666666667, 0.013).jpg'\n",
    "#考虑到百度AI平台的对并发量的限制，此处推荐分开处理，即获取response后不再重复对同一张照片进行处理\n",
    "response = BaiduMethod(filepath)\n",
    "if response:\n",
    "    print (response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API文档中用于对照参考的关键点识别示例照片：\n",
    "https://ai.bdstatic.com/file/52BC00FFD4754A6298D977EDAD033DA0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像截取部分的代码，分离出来方便随时进行调整，此版本的设计可获取到近乎整张脸的照片。\n",
    "def imgCrop(landmark,img): \n",
    "    box = (landmark[0]['x'],landmark[24]['y'],landmark[12]['x'],landmark[6]['y'])\n",
    "    img2 = img.crop(box)\n",
    "#     img2.show() #实时显示切割图片方便微调\n",
    "    img3.save(save_path+file+'.jpg')\n",
    "    \n",
    "#数据集获取方式一，对应脸部照片-鼠标坐标的格式\n",
    "def dataset1(path,save_path):\n",
    "    dirs = os.listdir(path)\n",
    "    for file in dirs:\n",
    "        filepath = os.path.join(path,file)\n",
    "        response = BaiduMethod(filepath)\n",
    "        if response and response.json()['error_code']==0:#成功收到且未报错\n",
    "            landmark = response.json()['result']['face_list'][0]['landmark72']\n",
    "            img = Image.open(filepath)\n",
    "            imgCrop(landmark,img)\n",
    "\n",
    "#数据集获取方式一，对应面部参数-鼠标坐标的格式\n",
    "def dataset2(path,save_path):\n",
    "    dirs = os.listdir(path)\n",
    "    rows = []\n",
    "    for file in dirs:\n",
    "        filepath = os.path.join(path,file)\n",
    "        response = BaiduMethod(filepath)\n",
    "        if response and response.json()['error_code']==0:#成功收到且未报错\n",
    "            landmark = response.json()['result']['face_list'][0]['landmark72']\n",
    "#           参数一：左半脸与右半脸宽度之比（相对观察者而言的左右）\n",
    "            paramX = abs(landmark[0]['x']-landmark[57]['x'])/abs(landmark[12]['x']-landmark[57]['x'])\n",
    "#           参数二：鼻尖与眼部上侧坐标纵坐标差值(建议进行进一步改进)\n",
    "            eyeY = (landmark[15]['y'] + landmark[32]['y'])/2\n",
    "            paramY = eyeY - landmark[57]['y']\n",
    "#         (-0.5206666666666667, 0.013).jpg\n",
    "            mouseX = file[1:file.index(',')]\n",
    "            mouseY = file[file.index(',')+1:file.index(')')]\n",
    "            #将四个参数保存到列表中\n",
    "            rows.append([paramX,paramY,mouseX,mouseY])\n",
    "    headers = ['paramX','paramY','mouseX','mouseY']\n",
    "    with open('dataset.csv','w') as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        f_csv.writerow(headers)\n",
    "        f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/UserData/Documents/Jupyter/EyeTrack/DataSet/' #待遍历目录路径\n",
    "save_path = 'D:/UserData/Documents/Jupyter/EyeTrack/DataSet02/'#保存文件目录\n",
    "dataset2(path,save_path) #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
