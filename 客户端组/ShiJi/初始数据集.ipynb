{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8/21/2020\n",
    "\n",
    "由于现阶段暂未解决脸部特征追踪的实现，初始数据集定为人脸照片+鼠标坐标，鼠标坐标数据保存为照片的命名格式\n",
    "等待后续技术跟进后，可将人脸图片转化为大小固定的矩阵作为输入，将鼠标坐标作为标签，则可直接输入模型进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyAutoGUI是一个纯Python的GUI自动化工具，其目的是可以用程序自动控制鼠标和键盘操作，多平台支持（Windows，OS X，Linux）。\n",
    "#cv2即opencv2，用于实现电脑摄像头的调用等操作\n",
    "import pyautogui as pag\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "屏幕分辨率为： 3000 × 2000\n",
      "当前鼠标位置为：( 2068 , 719 )\n"
     ]
    }
   ],
   "source": [
    "#获取当前屏幕分辨率\n",
    "screenWidth,screenHeight = pag.size()\n",
    "#获取当前鼠标位置\n",
    "currMouseX,currMouseY = pag.position()\n",
    "print(\"屏幕分辨率为：\",screenWidth,\"×\",screenHeight)\n",
    "print(\"当前鼠标位置为：(\",currMouseX,\",\",currMouseY,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前鼠标位置为：( 2129 , 1209 )\n",
      "当前鼠标位置为：( 1944 , 1562 )\n",
      "当前鼠标位置为：( 1393 , 1601 )\n",
      "当前鼠标位置为：( 1856 , 43 )\n",
      "当前鼠标位置为：( 1342 , 1684 )\n",
      "当前鼠标位置为：( 1342 , 1684 )\n",
      "当前鼠标位置为：( 1606 , 1307 )\n",
      "当前鼠标位置为：( 2166 , 429 )\n",
      "当前鼠标位置为：( 2184 , 412 )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-98a3d82929e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcurrMouseX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrMouseY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"当前鼠标位置为：(\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrMouseX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrMouseY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\")\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#休眠一秒\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    currMouseX,currMouseY = pag.position()\n",
    "    print(\"当前鼠标位置为：(\",currMouseX,\",\",currMouseY,\")\")\n",
    "    time.sleep(1)#休眠一秒"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑到不同设备的兼容性，且便于模型的学习效果，以屏幕中心点（screenWidth/2，screenHight/2）为原点，将屏幕划分为四个不同的象限，将鼠标坐标转化为相对于原点的相对坐标，并进行归一化处理。\n",
    "注意：此处的象限暂定为与数学中象限一致，即左上为第一象限，X轴向左为正方向，Y轴向上为正方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.798, 0.431)\n"
     ]
    }
   ],
   "source": [
    "screenWidth,screenHeight = pag.size()\n",
    "\n",
    "#屏幕原点位置\n",
    "origin = (screenWidth/2,screenHeight/2)\n",
    "\n",
    "currMouseX,currMouseY = pag.position()\n",
    "currMouse = ((currMouseX-origin[0])/origin[0],(origin[1]-currMouseY)/origin[1])\n",
    "print(currMouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.9993333333333333, 0.996)\n",
      "(0.9993333333333333, 0.998)\n",
      "(0.99, -0.973)\n",
      "(-1.0, -0.922)\n",
      "(-0.8873333333333333, 0.236)\n",
      "(0.5226666666666666, 0.431)\n",
      "(0.41533333333333333, -0.851)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui as pag\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "screenWidth,screenHeight = pag.size()\n",
    "#屏幕原点位置\n",
    "origin = (screenWidth/2,screenHeight/2)\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27: #Esc键退出\n",
    "        break\n",
    "    elif k==32:#空格键保存图片\n",
    "        currMouseX,currMouseY = pag.position()\n",
    "        currMouse = ((currMouseX-origin[0])/origin[0],(origin[1]-currMouseY)/origin[1])\n",
    "        print(currMouse)\n",
    "        cv2.imwrite('D:/UserData/Documents/Jupyter/EyeTrack/DataSet/'+str(currMouse)+'.jpg',frame)\n",
    "    cv2.imshow(\"capture\", frame)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
