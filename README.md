# SIT项目：基于面部口眼行为识别的无障碍服务 

## 项目简介：

​		截止2018年，中国肢体残障人士逼近2900万，是所有残障人群中所占比例最大的群体，其中手部或身体移动困难人群又超过其中65%，值得被特别关注。
​		互联网+时代，智能设备接入网络已成为当前中国日常必需。但是无论是电脑、平板，或智能手机的使用，都无法摆脱对“手”的使用要求，这对手部残障或肢体移动困难人群不够友好。
​		本项目试图以面部行为——眼球运动和嘴部张合行为结合来替代手部触屏或者鼠标移动操作，为前述肢体残障人群提供生活便利，也可以为普通民众提供更多智能控制接入的选择。



## 研究目的：

​		通过摄像头智能采集用户眼部行为，并区别看时间、阅读时的一般眼部行为，对眼球行为进行即时分析，并在必要的时候结合用户嘴部张合行为，区别于讲话时的一般嘴部行为，取代手部触屏或鼠标移动等普通操作，同样适合嘈杂环境语音难以识别的日常情景



## 研究内容：

1. 面部识别，对使用者进行身份确认
2. 眼球行为追踪，含多种眼球运动模式即时识别，包括眼球左/右移动，眼球转动，停留方向，并与正常阅读时的眼球行为进行区分
3. 嘴部行为识别，包括张、合等
4. 普通（前置）摄像头即可完成对上述行为的采集



## 进度情况：

- 学习Python
- 通过谷歌机器学习速学课程学习机器学习基础知识：
  https://developers.google.cn/machine-learning/crash-course
- 通过观看慕课学习搭建基础模型
  https://www.icourse163.org/learn/PKU-1002536002?tid=1452937471#/learn/content?type=detail&id=1229057942
- 搭建第一个机器学习模型——数字识别模型
- 小组分组：模型搭建小组，收集数据小组
  - 模型搭建小组（LiuHongyuan，ZhangHaoTian，ZhaiYu）：
    - 实现了数字识别模型的搭建，可以实现输入手写数字图片来识别相应的数字，并且能够反馈模型的精确率。
    - 尝试搭建眼球追踪的模型，但是在训练二维数组数据出现了障碍
  - 收集数据小组（ShiJi，ZhangJiwei）：
    - 通过摄像头获取人脸图片，并且采用百度API截取眼部区域
    - 实现按下空格即可抓取一次眼部图片的功能，实现了数据收集的基本功能



